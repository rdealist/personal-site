# 数据处理与特征工程

## 1. 什么是数据增强(Data Augmentation),它如何提升模型鲁棒性?

**定义**: 通过对原始数据进行变换,人工扩充训练数据集。

**常见增强方法**:

| 领域 | 增强技术 |
|------|----------|
| **图像** | 旋转、翻转、裁剪、缩放、颜色变换、噪声添加 |
| **文本** | 同义词替换、回译、随机删除/插入/交换 |
| **音频** | 加噪、变速、变调、时间拉伸 |

**为什么提升鲁棒性**:
1. **增加多样性**: 模型见过更多变化
2. **减少过拟合**: 不依赖特定数据模式
3. **隐式正则化**: 增加训练难度

**进阶方法**:
- **Mixup**: 混合两个样本及其标签
- **CutMix**: 裁剪并粘贴图像区域
- **AutoAugment**: 自动搜索最优增强策略

---

## 2. 特征工程(Feature Engineering)在深度学习时代还重要吗?

**答案**: 重要性降低,但未消失。

**变化对比**:

| 时代 | 特征工程角色 |
|------|--------------|
| 传统ML | 核心,决定模型上限 |
| 深度学习 | 辅助,端到端学习特征 |

**仍然重要的场景**:

| 场景 | 原因 |
|------|------|
| 表格数据 | 深度学习优势不明显 |
| 小数据集 | 先验知识更有价值 |
| 特定领域 | 领域专家知识无法自动学习 |
| 模型可解释性 | 人工特征更易解释 |

**现代特征工程**:
- 数据预处理仍是关键
- 模型输入设计影响效果
- 多模态特征融合策略
- 自动特征工程工具 (AutoML)

---

## 3. 归一化(Normalization)和标准化(Standardization)有什么区别?

**公式对比**:

| 方法 | 公式 | 结果范围 |
|------|------|----------|
| **归一化 (Min-Max)** | (x - min) / (max - min) | [0, 1] |
| **标准化 (Z-score)** | (x - μ) / σ | 均值0,标准差1 |

**选择依据**:

| 场景 | 推荐方法 |
|------|----------|
| 需要固定范围 | 归一化 |
| 数据有异常值 | 标准化(更鲁棒) |
| 神经网络输入 | 两者皆可,标准化更常用 |
| 图像像素值 | 归一化到[0,1]或[-1,1] |

**重要原则**:
- 在训练集上计算统计量
- 用相同参数处理验证/测试集
- 不同特征独立处理

---

## 4. 独热编码(One-Hot Encoding)如何将类别变量转化为数字?

**原理**: 每个类别用一个二进制向量表示,只有对应位置为1。

**示例**:
```
类别: [红, 绿, 蓝]

红 → [1, 0, 0]
绿 → [0, 1, 0]
蓝 → [0, 0, 1]
```

**优点**:
- 不引入虚假的大小关系
- 兼容大多数算法
- 简单直观

**缺点**:
- 高维稀疏 (类别多时)
- 无法表达类别间相似性
- 增加特征维度

**替代方法**:

| 方法 | 适用场景 |
|------|----------|
| **Label Encoding** | 有序类别 |
| **Target Encoding** | 高基数类别 |
| **Embedding** | 深度学习场景 |

---

## 5. 降维(Dimensionality Reduction)技术如何帮助处理高维数据?

**高维数据的问题**:
- 维度灾难: 样本变得稀疏
- 计算成本高
- 过拟合风险增加
- 难以可视化

**降维方法分类**:

| 类型 | 方法 | 特点 |
|------|------|------|
| **线性** | PCA, LDA | 保持线性关系 |
| **非线性** | t-SNE, UMAP | 保持局部结构 |
| **特征选择** | LASSO, 互信息 | 选择重要特征 |

**降维的收益**:
1. 降低计算复杂度
2. 去除噪声和冗余
3. 便于可视化
4. 可能提升模型性能

**注意事项**: 降维可能丢失信息,需权衡维度和信息保留。

---

## 6. PCA(主成分分析)和t-SNE在降维时有什么不同的应用场景?

**核心对比**:

| 方面 | PCA | t-SNE |
|------|-----|-------|
| **类型** | 线性 | 非线性 |
| **目标** | 最大化方差 | 保持局部相似性 |
| **可逆性** | 可逆 | 不可逆 |
| **速度** | 快 | 慢 |
| **确定性** | 确定 | 随机(需设种子) |

**应用场景**:

| 场景 | 推荐方法 |
|------|----------|
| 特征预处理 | PCA |
| 高维数据可视化 | t-SNE/UMAP |
| 线性可分数据 | PCA |
| 复杂非线性结构 | t-SNE |
| 新数据投影 | PCA |
| 聚类结构探索 | t-SNE |

**实践建议**: 可视化时先用PCA降到50维,再用t-SNE降到2维。

---

## 7. 什么是数据标注(Data Annotation),为什么它在监督学习中如此关键?

**定义**: 为原始数据添加标签或注释,使其可用于监督学习。

**标注类型**:

| 任务 | 标注形式 |
|------|----------|
| 图像分类 | 类别标签 |
| 目标检测 | 边界框 + 类别 |
| 语义分割 | 像素级标签 |
| NLP分类 | 文本类别 |
| 命名实体 | 实体边界 + 类型 |

**为什么关键**:
1. **监督学习的基础**: 没有标签无法训练
2. **决定模型上限**: 标签质量决定模型质量
3. **成本占比高**: 往往是AI项目最大成本

**标注质量保障**:
- 清晰的标注指南
- 多人标注+一致性检查
- 专家审核
- 持续反馈改进

**趋势**: 半监督学习、自监督学习减少对标注的依赖

---

## 8. 如何处理数据集中的不平衡问题(Class Imbalance)?

**问题**: 某些类别样本远多于其他类别,模型倾向预测多数类。

**解决策略**:

**数据层面**:

| 方法 | 说明 |
|------|------|
| **过采样** | 增加少数类样本 (SMOTE) |
| **欠采样** | 减少多数类样本 |
| **数据增强** | 对少数类进行增强 |

**算法层面**:

| 方法 | 说明 |
|------|------|
| **类别权重** | 少数类损失赋予更高权重 |
| **Focal Loss** | 降低易分样本权重 |
| **代价敏感学习** | 不同类别不同误分代价 |

**评估指标选择**:
- 避免只看准确率
- 使用F1、AUC-ROC、Precision-Recall曲线
- 考虑业务需求选择阈值

---

## 9. 数据清洗(Data Cleaning)包括哪些关键步骤?

**主要步骤**:

| 步骤 | 内容 |
|------|------|
| **缺失值处理** | 删除、填充(均值/中位数/模型预测) |
| **异常值检测** | Z-score、IQR、孤立森林 |
| **重复数据** | 识别并去重 |
| **数据类型** | 转换为正确类型 |
| **格式统一** | 日期、文本格式标准化 |
| **错误修正** | 拼写错误、逻辑错误 |

**缺失值处理策略**:

| 情况 | 策略 |
|------|------|
| 随机缺失,占比小 | 删除该行 |
| 整列大量缺失 | 删除该特征 |
| 有规律的缺失 | 作为特征 |
| 可推断 | 模型填充 |

**注意事项**:
- 在训练集上确定清洗规则
- 记录所有清洗操作
- 验证清洗后数据的分布变化

---

## 10. 向量数据库(Vector Database)为什么对RAG应用至关重要?

**定义**: 专门为存储和检索高维向量优化的数据库。

**核心能力**:
```
查询向量 → 向量数据库 → 最相似的Top-K向量
```

**为什么对RAG至关重要**:

| RAG流程 | 向量数据库作用 |
|---------|----------------|
| 知识库构建 | 存储文档的嵌入向量 |
| 语义检索 | 快速找到与查询相关的文档 |
| 上下文增强 | 将检索结果注入提示词 |

**相比传统数据库**:

| 能力 | 传统DB | 向量DB |
|------|--------|--------|
| 语义搜索 | 不支持 | 核心功能 |
| 相似度查询 | 需额外处理 | 原生支持 |
| 高维索引 | 低效 | 专门优化(HNSW, IVF) |

**主流产品**: Pinecone, Milvus, Weaviate, Chroma, Qdrant, pgvector

**典型规模**: 可处理数十亿向量,毫秒级检索延迟
