# 核心概念与原理

## 1. AI、机器学习(ML)、深度学习(DL)三者之间的本质区别是什么?

**层级关系**: AI ⊃ ML ⊃ DL

| 概念 | 定义 | 核心特征 |
|------|------|----------|
| **AI** | 使机器表现出智能行为的技术总称 | 可基于规则、也可基于学习 |
| **ML** | AI的子集,通过数据学习规律而非显式编程 | 依赖特征工程,从数据中自动提取模式 |
| **DL** | ML的子集,使用多层神经网络自动学习特征 | 端到端学习,自动特征提取,需要大量数据 |

**本质区别**: AI是目标,ML是实现路径,DL是ML中最强大的工具。

---

## 2. 为什么说神经网络(Neural Network)是在"模仿"人脑,这种模仿的底层逻辑是什么?

**模仿的层面**:
- **结构模仿**: 人工神经元 ↔ 生物神经元;权重连接 ↔ 突触
- **信息处理**: 输入信号加权求和 → 激活函数(类似阈值电位) → 输出

**底层逻辑**:
```
输出 = 激活函数(Σ(输入 × 权重) + 偏置)
```

**关键差异**: 这是一种**功能性模仿**而非生物学复制。真实神经元有时序、化学信号等复杂机制,人工神经网络是高度简化的数学抽象。

---

## 3. 什么是人工通用智能(AGI)与人工超级智能(ASI),它们与当前的AI有何根本性差异?

| 类型 | 定义 | 能力边界 |
|------|------|----------|
| **当前AI (ANI)** | 窄域AI,专精于特定任务 | 只能做被训练的事情 |
| **AGI** | 通用智能,可执行任何人类智力任务 | 跨领域迁移、自主学习、抽象推理 |
| **ASI** | 超越人类最高智能水平 | 理论概念,尚未实现 |

**根本差异**: 当前AI缺乏**真正的理解、自主目标设定、跨领域泛化能力**。AGI需要具备常识推理、因果理解和元认知能力。

---

## 4. Token(令牌)在LLM中扮演什么角色,为什么它被称为AI的"饭量"?

**Token的本质**: 文本的最小处理单元,通常是词、子词或字符。

**作用**:
- 输入输出的计量单位
- 模型处理和生成文本的基本粒度
- 决定计费和上下文限制

**为什么是"饭量"**:
- **输入Token** = 模型需要"消化"的信息量
- **输出Token** = 模型"产出"的内容量
- Token数量直接决定**计算成本、响应速度、上下文容量**

**经验值**: 英文约1 token ≈ 4字符 ≈ 0.75词;中文约1-2字符 ≈ 1 token

---

## 5. Embedding(嵌入)如何将文字转化为数字向量,这个过程为什么对AI理解语言至关重要?

**转化过程**:
```
文字 → 查表/模型计算 → 高维向量 (如768维或更高)
```

**核心原理**: 将离散的符号映射到连续的向量空间,使得:
- **语义相似的词在空间中距离相近** (如"国王"和"女王")
- **支持数学运算** (著名案例: king - man + woman ≈ queen)

**为什么至关重要**:
1. 神经网络只能处理数值,Embedding是文字进入模型的"入口"
2. 捕获语义关系,实现语义理解而非简单字符串匹配
3. 作为下游任务的特征表示基础

---

## 6. Transformer架构为什么被认为是AI发展史上的革命性突破?

**革命性突破点**:

| 问题 | 之前方案 | Transformer解决方式 |
|------|----------|---------------------|
| 长距离依赖 | RNN逐步传递,信息衰减 | 注意力直接关联任意位置 |
| 并行计算 | RNN必须串行处理 | 完全并行,GPU友好 |
| 可扩展性 | 模型难以有效扩大 | 可扩展到千亿参数级别 |

**核心创新**:
- **自注意力机制**: 每个位置可以直接"看到"所有其他位置
- **位置编码**: 用数学方式注入序列位置信息
- 统一架构适用于NLP、CV、多模态等多个领域

---

## 7. 注意力机制(Attention Mechanism)的"注意力"到底在关注什么?

**关注的是**: 输入序列中**与当前处理位置最相关的部分**。

**计算过程**:
```
Attention(Q, K, V) = softmax(QK^T / √d_k) × V
```

**直观理解**:
- **Query(查询)**: "我在找什么?"
- **Key(键)**: "我有什么可以匹配的?"
- **Value(值)**: "匹配上了,返回什么内容?"

**实际效果**: 处理"银行"这个词时,注意力会根据上下文决定关注"河流"还是"金融"相关的词,从而理解是"河岸"还是"银行机构"。

---

## 8. 为什么LLM被称为"下一个词预测机器",但却能完成如此复杂的任务?

**训练目标**: 给定前文,预测下一个token的概率分布。

**为什么简单目标产生复杂能力**:

1. **压缩即理解**: 准确预测下一个词需要理解语法、语义、逻辑、事实知识
2. **规模效应**: 海量数据+巨大参数量,涌现出推理、创作等高级能力
3. **隐式学习**: 模型在预测过程中隐式学习了世界知识和推理模式

**类比**: 就像下棋AI只需学会"选择最佳下一步",但这需要理解整个棋局——预测的简单性掩盖了理解的复杂性。

---

## 9. 上下文窗口(Context Window)是什么,为什么它决定了AI的"记忆容量"?

**定义**: 模型单次处理能够"看到"的最大token数量。

**为什么是"记忆容量"**:
- 窗口内的内容 = AI能参考的全部信息
- 超出窗口的内容会被"遗忘"
- 决定了对话连贯性、长文档处理能力

**主流模型上下文窗口**:
| 模型 | 上下文窗口 |
|------|-----------|
| GPT-3.5 | 4K-16K |
| GPT-4 | 8K-128K |
| Claude 3 | 200K |
| Gemini 1.5 | 1M+ |

**权衡**: 更大窗口 = 更多计算成本 + 可能的注意力稀释

---

## 10. Temperature(温度)参数如何控制AI输出的创造性和随机性?

**数学原理**:
```
P(token) = softmax(logits / temperature)
```

**效果对比**:

| Temperature | 效果 | 适用场景 |
|-------------|------|----------|
| 0 | 确定性输出,总选概率最高的token | 代码生成、事实查询 |
| 0.7 | 平衡创造性和一致性 | 通用对话 |
| 1.0 | 标准采样 | 一般创作 |
| >1.0 | 高随机性,可能产生意外输出 | 头脑风暴、创意写作 |

**直观理解**: 温度越低,概率分布越"尖锐"(高概率词更突出);温度越高,分布越"平坦"(低概率词也有机会被选中)。
